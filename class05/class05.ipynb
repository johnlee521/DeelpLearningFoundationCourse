{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras已经集成了MNIST数据库，使用以下命令可以导入MNIST数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看training_images 和 training_labels 类型，并从 training_images 里随机选取一张图片，显示出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training_images {} '.format(training_images.shape))\n",
    "print('training_labels {} '.format(training_labels.shape))\n",
    "print('test_images {} '.format(test_images.shape))\n",
    "print('test_labels {} '.format(test_labels.shape))\n",
    "\n",
    "training_random = np.random.randint(60000)\n",
    "plt.imshow(training_images[training_random],cmap=plt.cm.binary)\n",
    "plt.xlabel(training_labels[training_random]).set_color('white')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从 training_images 里随机选取25张图片，并显示出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "i = 0\n",
    "for x in np.random.randint(60000, size=(25)):\n",
    "    image = training_images[x]\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image, cmap=plt.cm.binary)\n",
    "    plt.xlabel(training_labels[x]).set_color('white')\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像归一化处理，因为每个像素是8bit，最大值为255,所以每个像素都除以255. 使得每个像素的取值范围从[0-255]变成[0-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 输入层，隐藏层，输出层，并使用Sequential类构建成神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_layer  = tf.keras.layers.Flatten()\n",
    "hidden_layer = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "output_layer = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "model = tf.keras.models.Sequential([input_layer, hidden_layer, output_layer])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是softmax演示代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0]\n",
    "probability = np.exp(x) / np.sum(np.exp(x))\n",
    "print(x)\n",
    "print(probability)\n",
    "\n",
    "softmax = np.zeros(len(probability))\n",
    "softmax[probability.argmax()] = 1\n",
    "print(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "指定 损失函数loss function、优化器optimizer 和 metrics。metrics里的accuracy让神经网络模型在训练时候，同时计算每次训练数据的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(training_images, training_labels, epochs=5, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画出神经网络模型在训练的时候，每次迭代时训练数据的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试数据集的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加神经元，减少神经元，accuracy的变化。\n",
    "\n",
    "增加epochs次数，减少epochs次数，accuracy变化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过拟合 overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "validation_images = training_images[50000:60000]\n",
    "validation_labels = training_labels[50000:60000]\n",
    "\n",
    "training_images = training_images[0:50000]\n",
    "training_labels = training_labels[0:50000]\n",
    "\n",
    "input_layer  = tf.keras.layers.Flatten()\n",
    "hidden_layer = tf.keras.layers.Dense(64, activation=tf.nn.relu)\n",
    "output_layer = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "model = tf.keras.models.Sequential([input_layer, hidden_layer, output_layer])\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=100, batch_size=512, validation_data=(validation_images, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history \n",
    "loss_values = history_dict['loss'] \n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'g', label='Training loss') \n",
    "plt.plot(epochs, val_loss_values, 'r', label='Validation loss') \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('Loss') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history \n",
    "acc = history_dict['accuracy'] \n",
    "val_acc = history_dict['val_accuracy']\n",
    "plt.plot(epochs, acc, 'g', label='Training acc') \n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc') \n",
    "plt.title('Training and validation accuracy') \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy') \n",
    "plt.ylim([0.90, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
